{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ji1AYDDE-d",
        "outputId": "6224cd55-111e-44be-f578-d568fba2dcc5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJgGqyxnE4zi",
        "outputId": "cb2d3041-cb73-4099-d960-86cd9082b4a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from torch.utils.data import random_split, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "rjESJs8ECD-Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "EXTRACTION_DIRECTORY = \"/content/drive/My Drive/ChefAI/rawdata\"\n",
        "BATCH_SIZE = 6\n",
        "EPOCHS = 2\n",
        "MAX_LENGTH = 512\n",
        "LEARNING_RATE = 5e-4\n",
        "WARMUP_STEPS = 1e2\n",
        "EPSILON = 1e-8\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "iQXPPQkNOJfk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data\n",
        "json_files_paths = [os.path.join(EXTRACTION_DIRECTORY, file_name) for file_name in os.listdir(EXTRACTION_DIRECTORY) if file_name.endswith('.json')]\n",
        "recipes_data = []\n",
        "for json_file_path in json_files_paths:\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "        recipes_data.extend(list(data.values()))\n",
        "\n",
        "# Showing the number of recipes and a sample recipe\n",
        "num_recipes = len(recipes_data)\n",
        "sample_recipe = recipes_data[40000] if recipes_data else \"No recipes found\"\n",
        "\n",
        "num_recipes, sample_recipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDD27oOHN376",
        "outputId": "03f2c483-3318-4cab-feb1-427f3ab08f98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125164,\n",
              " {'title': 'Toffee Bar Coffee Cake',\n",
              "  'ingredients': ['2 cups all-purpose flour ADVERTISEMENT',\n",
              "   '3/4 cup white sugar ADVERTISEMENT',\n",
              "   '3/4 cup brown sugar ADVERTISEMENT',\n",
              "   '6 tablespoons butter, softened ADVERTISEMENT',\n",
              "   '1 cup milk ADVERTISEMENT',\n",
              "   '2 teaspoons baking powder ADVERTISEMENT',\n",
              "   '1 teaspoon vanilla extract ADVERTISEMENT',\n",
              "   '5 (1.4 ounce) bars chocolate covered toffee bars, chopped ADVERTISEMENT',\n",
              "   '1 egg ADVERTISEMENT',\n",
              "   '1/2 cup chopped, unsalted dry-roasted peanuts ADVERTISEMENT',\n",
              "   'ADVERTISEMENT'],\n",
              "  'instructions': 'Preheat oven to 350 degrees F (175 degrees C). Grease and flour a 9x13 inch pan. Crush toffee bars into small bits and set aside.\\nIn a large bowl, combine flour, sugar, brown sugar and butter; mix on low speed with an electric mixer until crumbly. Remove 1/2 cup of crumb mixture and set aside to be used for topping. Add milk, baking powder, vanilla, egg, and 1/2 cup of the crushed toffee bars; beat at low speed until well-mixed. Increase speed to medium, and beat for 1 minute. Spread batter evenly in 9x13 inch pan.\\nTo make the topping: In a small bowl, mix nuts, remaining chopped toffee bars, and reserved 1/2 cup crumb mixture. Sprinkle mixture evenly over batter in pan.\\nBake for 30 minutes, or until it tests done. Cool cake completely in pan on rack. Make about 2 1/2 hours before serving, or early the in day.\\n',\n",
              "  'picture_link': '8PetsKizC8qer3lwIaIfsSfyYDY0riq'})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocess_raw_data(recipes_data):\n",
        "    '''\n",
        "    Take a list of recipe data and preprocess it,\n",
        "    return a list of recipe instances with special tokens\n",
        "\n",
        "    parameter: list of recipe data\n",
        "\n",
        "    return: recipe instance list\n",
        "    '''\n",
        "    raw_list = []\n",
        "    for recipe in recipes_data:\n",
        "        # try/except will filter out recipes that don't have title, ingredients or instructions\n",
        "        try:\n",
        "            title = recipe['title'].replace(\"ADVERTISEMENT\", \"\")\n",
        "            ingredient_list = recipe['ingredients']\n",
        "            ingredients = \"\"\n",
        "            for ingredient in ingredient_list:\n",
        "                ingredient = ingredient.replace(\"ADVERTISEMENT\", \"\")\n",
        "                if ingredient != \"\":\n",
        "                    ingredients += ingredient + \", \"\n",
        "            instructions = recipe['instructions'].replace(\"ADVERTISEMENT\", \"\")\n",
        "            recipe_instance = '<|startofrecipe|>' + title + '<|startofingre|>' + ingredients + '<|startofinstruc|>' + instructions + '<|endofrecipe|>'\n",
        "            if len(recipe_instance) <= 2000:\n",
        "                raw_list.append(recipe_instance)\n",
        "\n",
        "        except:\n",
        "            continue\n",
        "    return raw_list\n",
        "\n",
        "# Apply preprocessing to the recipe data\n",
        "preprocessed_recipes = load_preprocess_raw_data(recipes_data)"
      ],
      "metadata": {
        "id": "x-o-3ZqCO2tw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print 5 random recipes\n",
        "for _ in range(5):\n",
        "    print(random.choice(preprocessed_recipes))\n",
        "    print('-' * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vkPSqVMCqkO",
        "outputId": "d816278a-0eb8-4af9-a0d5-9b041670a113"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|startofrecipe|>Scones<|startofingre|>About 11 ounces all-purpose flour, About 5 ounces sugar, 2 eggs, 1 teaspoon baking powder, About 3 ounces butter, Milk, <|startofinstruc|>Preheat oven to 350 degrees F.\n",
            "Mix all ingredients. Pour milk into the mix little by little until you have a dough, (a little stiff, not dry). Lightly flour your hands and roll the dough into little balls. Bake for about 12 minutes. Serve immediately.\n",
            "It can be served plain, with butter or jam.<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<|startofrecipe|>Chicken Alfredo with Fettuccini Noodles<|startofingre|>1 pound fettuccini pasta , 1 1/2 cups butter, divided , 1 pound skinless, boneless chicken breast halves - cut into cubes , 2 (16 ounce) containers whole milk ricotta cheese , 1 pint heavy cream , 1 teaspoon salt , 1 cup grated Parmesan cheese , <|startofinstruc|>Bring a large pot of lightly salted water to a boil. Add fettuccini and cook for 8 to 10 minutes or until al dente; drain.\n",
            "Melt 2 tablespoons butter in a large skillet over medium heat. Saute chicken until no longer pink and juices run clear.\n",
            "In a large saucepan combine ricotta cheese, cream, salt, Parmesan cheese and remaining butter. Cook over medium heat until well combined, about 10 minutes. Stir in cooked fettuccini and chicken; cook until heated through.\n",
            "<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<|startofrecipe|>Chestnuts and Wild Mushrooms<|startofingre|>2 tablespoons olive oil, 1 clove garlic, finely sliced, 8 ounces Shiitake mushrooms, trimmed and sliced, 15 ounces drained canned chestnuts packed in water, Salt and freshly ground black pepper, <|startofinstruc|>Heat the olive oil in a skillet and slowly let the garlic get brown. Saute the Shiitake until soft (adding a spoonful of water if necessary so they don't burn). Add the chestnuts and saute just to reheat them and season well with salt and lots of ground black pepper.<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<|startofrecipe|>Chicken, Sweet Potato and Spinach Soup<|startofingre|>3 (14.5 ounce) cans chicken stock , 1 sweet potato, peeled and cubed , 3 cups fresh baby spinach leaves , 1 cup cooked roast chicken meat , 1 clove garlic, minced , salt and ground black pepper to taste , <|startofinstruc|>Heat chicken stock and sweet potato in a stockpot over high heat. Cook until sweet potato is soft enough to pierce with a fork, about 10 minutes. Stir in spinach, chicken, and garlic; simmer until spinach is wilted and broth is reduced slightly, 10 to 15 minutes more. Season with salt and pepper.\n",
            "<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<|startofrecipe|>Grilled Scallops with Curried Tomato Coulis <|startofingre|>2 large shallots, sliced thin, 2 tablespoons olive oil, 1 teaspoon mustard seeds, 1 1/2 teaspoons curry powder, 1/2 teaspoon sugar, 6 plum tomatoes, seeded and chopped, 2 teaspoons balsamic vinegar, vegetable oil for brushing the grill pan, 3/4 pound sea scallop, <|startofinstruc|>In a skillet cook the shallots in the olive oil over moderate heat, stirring, until they are softened, stir in the mustard seeds and the curry powder, and cook the mixture, stirring, for 1 minute. Stir in the sugar, the tomatoes, and salt and pepper to taste and cook the mixture, stirring, for 2 minutes, or until the tomatoes begin to release their juices. Stir in the balsamic vinegar and keep the coulis warm. Heat a well-seasoned ridged grill pan over moderately high heat until it is hot and brush it with vegetable oil. Add the scallops, patted dry, and grill them for 2 1/2 minutes on each side, or until they are just firm. Divide the coulis between 2 plates and top each serving with half the scallops.\n",
            "In a skillet cook the shallots in the olive oil over moderate heat, stirring, until they are softened, stir in the mustard seeds and the curry powder, and cook the mixture, stirring, for 1 minute. Stir in the sugar, the tomatoes, and salt and pepper to taste and cook the mixture, stirring, for 2 minutes, or until the tomatoes begin to release their juices. Stir in the balsamic vinegar and keep the coulis warm. Heat a well-seasoned ridged grill pan over moderately high heat until it is hot and brush it with vegetable oil. Add the scallops, patted dry, and grill them for 2 1/2 minutes on each side, or until they are just firm. Divide the coulis between 2 plates and top each serving with half the scallops.<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and distillgpt2 model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Add special tokens\n",
        "special_tokens_dict = {\n",
        "    'bos_token': '<|startofrecipe|>',\n",
        "    'eos_token': '<|endofrecipe|>',\n",
        "    'pad_token': '<|pad|>',\n",
        "    'additional_special_tokens': ['<|startofingre|>', '<|startofinstruc|>']\n",
        "}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "print('Number of added special tokens:', num_added_toks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAOkxSQZQYA6",
        "outputId": "72ab427f-ed97-4881-c41e-ac1a30fdb8c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of added special tokens: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RecipeDataset(Dataset):\n",
        "    def __init__(self, recipes, tokenizer, max_length):\n",
        "        self.recipes = recipes\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.recipes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        recipe = self.recipes[idx]\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            recipe,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze()\n",
        "        }"
      ],
      "metadata": {
        "id": "QfGR1H0MA9HN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = RecipeDataset(preprocessed_recipes, tokenizer, max_length=MAX_LENGTH)\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=BATCH_SIZE)\n",
        "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "UzquJVOv-nrg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=EPSILON)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=len(train_dataloader) * EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuJZqu09BhIt",
        "outputId": "250a8f79-7848-4df6-fae6-8701d3deeab9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, tokenizer, save_path):\n",
        "    model.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "\n",
        "def train_and_save_best_model(model, tokenizer, train_dataloader, val_dataloader, optimizer, scheduler, epochs, device, save_path):\n",
        "    best_val_loss = float('inf')\n",
        "    training_stats = []\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "        print(f'\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        progress_bar = tqdm(train_dataloader, desc=\"Training\", leave=False)\n",
        "        for step, batch in enumerate(progress_bar):\n",
        "            b_input_ids, b_attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "            outputs = model(b_input_ids, attention_mask=b_attention_mask, labels=b_input_ids)\n",
        "            loss = outputs.loss\n",
        "            total_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            progress_bar.set_postfix({'Loss': f\"{loss.item():.4f}\"}, refresh=True)\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"\\nRunning Validation...\")\n",
        "        model.eval()\n",
        "        total_eval_loss = 0\n",
        "        progress_bar = tqdm(val_dataloader, desc=\"Validating\", leave=False)\n",
        "\n",
        "        for step, batch in enumerate(progress_bar):\n",
        "            b_input_ids, b_attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(b_input_ids, attention_mask=b_attention_mask, labels=b_input_ids)\n",
        "                loss = outputs.loss\n",
        "                total_eval_loss += loss.item()\n",
        "\n",
        "            progress_bar.set_postfix({'Loss': f\"{loss.item():.4f}\"}, refresh=True)\n",
        "\n",
        "        avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "        print(f\"\\n  Validation Loss: {avg_val_loss:.2f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            save_model(model, tokenizer, save_path)\n",
        "            print(\"  New best model saved!\")\n",
        "\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'Epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Validation Loss': avg_val_loss,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(\"\\nTraining complete!\")\n",
        "\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "    df_stats = df_stats.set_index('Epoch')\n",
        "    print(df_stats)\n",
        "\n",
        "    sns.set(style='whitegrid', palette='deep', font_scale=1.1, rc={\"figure.figsize\": [8, 6]})\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label='Training')\n",
        "    plt.plot(df_stats['Validation Loss'], 'g-o', label='Validation')\n",
        "    plt.title('Training & Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.xticks(list(range(1, epochs+1)))\n",
        "    plt.show()\n",
        "\n",
        "save_path = \"/content/drive/My Drive/ChefAI/best_model\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "train_and_save_best_model(model, tokenizer, train_dataloader, val_dataloader, optimizer, scheduler, EPOCHS, DEVICE, save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "go4DanN0Ia6G",
        "outputId": "f7a00392-135b-45d0-e4b3-55e768c201a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c377aa6095b3>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/ChefAI/best_model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0mtrain_and_save_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recipe(model, tokenizer, ingredients, max_length=100):\n",
        "    prompt = \"<|startofrecipe|><|startofingre|>\" + ingredients + \"<|startofinstruc|>\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(DEVICE)\n",
        "\n",
        "    output_ids = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        num_beams=5,\n",
        "        no_repeat_ngram_size=2,\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "\n",
        "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return output\n",
        "\n",
        "def test_recipe_generation(ingredients):\n",
        "    ingredients_text = \", \".join(ingredients)\n",
        "    recipe = generate_recipe(model, tokenizer, ingredients_text)\n",
        "    print(\"Generated Recipe:\")\n",
        "    print(recipe)\n",
        "\n",
        "# Example usage\n",
        "test_recipe_generation([\"chicken\", \"onions\", \"garlic\"])\n"
      ],
      "metadata": {
        "id": "UXVlqVj0CzQr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}