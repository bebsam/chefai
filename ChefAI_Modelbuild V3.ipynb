{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ji1AYDDE-d",
        "outputId": "9ce0d409-6f5f-4f05-d884-33d0e0f2bd2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJgGqyxnE4zi",
        "outputId": "261bf889-2176-4966-f842-15552086ae57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rjESJs8ECD-Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2LMHeadModel\n",
        "from torch.utils.data import random_split, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iQXPPQkNOJfk"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "EXTRACTION_DIRECTORY = \"/content/drive/My Drive/ChefAI/dataset\"\n",
        "CSV_FILE_NAME = \"full_dataset.csv\"\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 2\n",
        "MAX_LENGTH = 512\n",
        "LEARNING_RATE = 2e-4\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "EPSILON = 1e-8\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDD27oOHN376",
        "outputId": "1fbb3399-7ceb-4a0d-bd21-9031e9877050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0                                                717506\n",
            "title                                           Crazy Corn Bread\n",
            "ingredients    [\"2 boxes Jiffy cornbread mix\", \"2 eggs\", \"1 (...\n",
            "directions     [\"Mix all together. Bake at 350\\u00b0 for 45 m...\n",
            "link             www.cookbooks.com/Recipe-Details.aspx?id=118444\n",
            "source                                                  Gathered\n",
            "NER              [\"cornbread mix\", \"eggs\", \"corn\", \"sour cream\"]\n",
            "Name: 717506, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Loading the data\n",
        "csv_file_path = os.path.join(EXTRACTION_DIRECTORY, CSV_FILE_NAME)\n",
        "recipes_data = pd.read_csv(csv_file_path)\n",
        "\n",
        "sampled_recipes_data = recipes_data.sample(n=250000, random_state=83)\n",
        "\n",
        "sample_recipe = sampled_recipes_data.iloc[1000]\n",
        "print(sample_recipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-o-3ZqCO2tw",
        "outputId": "cedf0b96-85ae-4c94-9da3-6a5c4e9c313d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of preprocessed recipes: 250000\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def load_preprocess_raw_data(recipes_data):\n",
        "    raw_list = []\n",
        "    for _, recipe in recipes_data.iterrows():\n",
        "        try:\n",
        "            title = recipe['title'].strip().lower()\n",
        "            ingredients = \", \".join(eval(recipe['ingredients'])).strip().lower()\n",
        "            # Convert the string representation of directions to a list and then join into a single string.\n",
        "            directions = \" \".join(eval(recipe['directions'])).strip().lower()\n",
        "            # Split the directions into sentences\n",
        "            directions_sentences = re.split(r'\\. +', directions)\n",
        "            # Enumerate the sentences to create a numbered list, with the first item on a new line\n",
        "            numbered_directions = \"\\n\".join(f\"{i+1}. {sentence.strip()}\"\n",
        "                                            for i, sentence in enumerate(directions_sentences)\n",
        "                                            if sentence)  # Ensure no empty strings are added\n",
        "            recipe_instance = '<|startofrecipe|>' + title + '<|startofingre|>' + ingredients + '<|startofinstruc|>' + numbered_directions + '<|endofrecipe|>'\n",
        "            raw_list.append(recipe_instance)\n",
        "        except Exception as e:\n",
        "            print(f\"An exception occurred for a row: {e}\")\n",
        "            continue\n",
        "    return raw_list\n",
        "\n",
        "# Preprocess the sampled recipes\n",
        "preprocessed_recipes = load_preprocess_raw_data(sampled_recipes_data)\n",
        "\n",
        "# Print the number of preprocessed recipes\n",
        "print(f\"Number of preprocessed recipes: {len(preprocessed_recipes)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vkPSqVMCqkO",
        "outputId": "2e461686-5f83-44e2-dfe9-87b7ecbd4ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|startofrecipe|>breakfast goulash<|startofingre|>1 small onion, chopped, 1 lb ground sausage, 12 eggs, 1 cup shredded cheddar cheese<|startofinstruc|>1. cook sausage and onions on medium heat until sausage is no longer pink\n",
            "2. in a medium size bowl beat eggs (add two tablespoons of milk if desired) then add to sausage\n",
            "3. cook and scramble eggs until almost completely set\n",
            "4. add cheese and stir until eggs are done and cheese is melted.<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<|startofrecipe|>escabeche, sweet and sour<|startofingre|>500 grams any salt water fish, regular in size for each person, 1 bellpepper, red, 1 carrot, to taste salt<|startofinstruc|>1. wash the fish, clean and scale\n",
            "2. sprinkle salt and set aside\n",
            "3. prepare the spices: clean and cut\n",
            "4. set aside\n",
            "5. fry the fish and set aside\n",
            "6. drain the used cooking oil from frying\n",
            "7. from the same pan used in frying saute onions, garlic, ginger, carrots and bell pepper\n",
            "8. add half a cup of water, salt, oyster sauce, soy sauce and vinegar\n",
            "9. when it's about to boil add the fried fish and simmer for 3 minutes then serve.<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<|startofrecipe|>pesto chicken in slow cooker<|startofingre|>2 chicken breasts, (mine were frozen), 1 can chicken broth, 1.5 cups basil, 2 - 3 tblspns olive oil, 1/2 tblspn lemon juice, 2 cloves garlic, 1/2 cup pine nuts, 1/2 cup parmesean cheese, salt and pepper to taste<|startofinstruc|>1. put the basil and olive oil in your mini food processor and chop it up add in your lemon juice, garlic, salt and pepper, and about half of the pine nuts (you can add them all if you want, but i like to have some chunky ones in there)\n",
            "2. you can add about 1/2 a cup of parmesean too, but i was trying not to make it too cheesey\n",
            "3. and i think the cheese might melt weird if it's in the crock pot for too long\n",
            "4. blend it up, and throw in the extra pine nuts afterwards if you held them aside\n",
            "5. now open your broth and put it in your crock pot you can add less than a can if you're only going to cook the chicken for 6-8 hours\n",
            "6. i often have to leave mine for up to 10 hours, so i add more broth to keep it from drying out\n",
            "7. add the chicken in the pot\n",
            "8. throw your pesto on top of the chicken\n",
            "9. i added some leftover onions too\n",
            "10. set the crock pot to low\n",
            "11. come back about 7 1/2 hours later (again, add more or less broth depending on how long you're going to be gone and how strong you want the taste to be) throw some deeeelicious parmesean cheese on top of that baby\n",
            "12. and then let it cook for another fifteen minutes, or until the cheese turns into melty goodness serve over pasta, in a sandwich or with veggies\n",
            "13. spoon some of the pesto-y onion-y broth-y goodness on top for an extra treat<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<|startofrecipe|>roasted eggplant (aubergine) spread<|startofingre|>3 medium eggplants, peeled and sliced thinly (1/8-inch), 2 1/2 teaspoons salt, 10 garlic cloves, peeled, 2 tablespoons lemon juice, 3 tablespoons olive oil, 1/4 teaspoon salt, 1/4 teaspoon crushed red pepper flakes, roasted bell pepper, slices (optional), parmesan cheese (optional)<|startofinstruc|>1. sprinkle eggplant slices with 2 1/2 tsp salt and let stand for 30 minutes\n",
            "2. preheat oven to 450°f rinse eggplant and place on oiled baking sheets; add garlic\n",
            "3. bake 25 minutes or until the eggplant edges are crispy and the garlic us tender\n",
            "4. cool slightly so it can be handled; chop eggplant and garlic\n",
            "5. combine eggplant mixture, lemon juice, olive oil, 1/4 tsp salt, and crushed red pepper in a large bowl\n",
            "6. spoon onto crostini (or crackers, pita chips, etc) and garnish as desired.<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<|startofrecipe|>fettuccine with prawns, peas, tomatoes with cream sauce<|startofingre|>1/2 cup dry white wine, 1/2 cup dry vermouth, 2/3 pound linguine pasta, 4 teaspoons turmeric, 2 tablespoons olive oil, 1 pound prawns shelled leaving the tail intact, deveined, 2 teaspoons minced garlic, 1/2 cup minced onion, 1 cup heavy cream, 2 tomatoes large, internal seeds removes and chopped, 1 cup frozen peas<|startofinstruc|>1. in a small bowl let the saffron soak in the wine for 5 minutes\n",
            "2. in a large pot of boiling salted water cook the linguine, the frozen peas with the turmeric until al dente\n",
            "3. while the pasta is cooking, in a large skillet heat the olive oil over moderate heat until it is hot but not smoking and add the onions stirring for a 1 minute\n",
            "4. add the garlic, salt and pepper to taste\n",
            "5. add the fresh chopped tomatoes and cook for 3 to 5 minutes\n",
            "6. add the wine and cook for another 5 minutes\n",
            "7. add the cream and boil the mixture until the liquid is reduced by half\n",
            "8. add the prawns and cook until the prawns turn pink, 1 minute\n",
            "9. season to taste\n",
            "10. drain the pasta and place back in to the pot that they were just drained from\n",
            "11. add the prawn sauce to it and blend well.<|endofrecipe|>\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Print 5 random recipes\n",
        "for _ in range(5):\n",
        "    print(random.choice(preprocessed_recipes))\n",
        "    print('-' * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAOkxSQZQYA6"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the tokenizer and distillgpt2 model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Add special tokens\n",
        "special_tokens_dict = {\n",
        "    'bos_token': '<|startofrecipe|>',\n",
        "    'eos_token': '<|endofrecipe|>',\n",
        "    'pad_token': '<|pad|>',\n",
        "    'additional_special_tokens': ['<|startofingre|>', '<|startofinstruc|>']\n",
        "}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "print('Number of added special tokens:', num_added_toks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QfGR1H0MA9HN"
      },
      "outputs": [],
      "source": [
        "class RecipeDataset(Dataset):\n",
        "    def __init__(self, recipes, tokenizer, max_length):\n",
        "        self.recipes = recipes\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.recipes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        recipe = self.recipes[idx]\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            recipe,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#When retraining\n",
        "\n",
        "base_save_path = \"/content/drive/My Drive/ChefAI\"\n",
        "checkpoint_path = os.path.join(base_save_path, \"model_checkpoints\")\n",
        "best_model_path = os.path.join(base_save_path, \"best_model_for_inference\")\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(best_model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(best_model_path)\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRJxDHVApV7X",
        "outputId": "7115beb7-b672-4afb-f745-5ec614f66544"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UzquJVOv-nrg"
      },
      "outputs": [],
      "source": [
        "dataset = RecipeDataset(preprocessed_recipes, tokenizer, max_length=MAX_LENGTH)\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=BATCH_SIZE)\n",
        "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_TRAINING_STEPS = int(len(train_dataloader) / GRADIENT_ACCUMULATION_STEPS * EPOCHS)\n",
        "WARMUP_STEPS = int(0.1 * TOTAL_TRAINING_STEPS)\n",
        "\n",
        "# Initialize optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, eps=EPSILON)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=TOTAL_TRAINING_STEPS)"
      ],
      "metadata": {
        "id": "26i5M0Ftoyje"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UuJZqu09BhIt"
      },
      "outputs": [],
      "source": [
        "# Initialize GPT2 model\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "TOTAL_TRAINING_STEPS = int(len(train_dataloader) / GRADIENT_ACCUMULATION_STEPS * EPOCHS)\n",
        "\n",
        "# Initialize optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, eps=EPSILON)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=TOTAL_TRAINING_STEPS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "f562ecbf0b53463d80045d3d43cf9223",
            "ab6e9d122e2c4216aeb0b0284eec95eb",
            "cae8d6647ba74075ae9407cb21a0b720",
            "552187e68fca4cecb4c42886b6faea8b",
            "a107ae7eceeb4caf93b946a5e5b8cf14",
            "ae67bbd91584471ab77db0a736aac4f0",
            "2d36fedfd3bb49e8912038283aa7d9a9",
            "566dd6b7d85e4ac8859311c1c00d1ad2",
            "225f6e8bf876479aab8d042f6fa05d1f",
            "0c59454cc7a54dbda8a4d419fc85b949",
            "08f9c51057434a79bd815734fd89956d"
          ]
        },
        "id": "go4DanN0Ia6G",
        "outputId": "3ca477b8-73d0-4c4b-f848-a6543bcbfc86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded. Resuming training from epoch 1\n",
            "\n",
            "======== Epoch 1 / 2 ========\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/28125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f562ecbf0b53463d80045d3d43cf9223"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Function to load the model, optimizer, and scheduler states\n",
        "def load_checkpoint(model, optimizer, scheduler, tokenizer, checkpoint_path, best_model_path ):\n",
        "    checkpoint = torch.load(os.path.join(checkpoint_path, 'checkpoint.pth'), map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    tokenizer.from_pretrained(best_model_path)  # Assuming tokenizer config is saved here\n",
        "    return model, optimizer, scheduler, checkpoint['epoch'], checkpoint['best_val_loss']\n",
        "\n",
        "# Function to save the model, optimizer, and scheduler states\n",
        "def save_checkpoint(model, optimizer, scheduler, epoch, best_val_loss):\n",
        "    os.makedirs(checkpoint_path, exist_ok=True)\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'best_val_loss': best_val_loss,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, os.path.join(checkpoint_path, 'checkpoint.pth'))\n",
        "    print(f\"Checkpoint saved at epoch {epoch+1} with validation loss {best_val_loss}\")\n",
        "\n",
        "# Function to save the best model for inference\n",
        "def save_best_model_for_inference(model, tokenizer, best_model_path):\n",
        "    os.makedirs(best_model_path, exist_ok=True)\n",
        "    model.save_pretrained(best_model_path)\n",
        "    tokenizer.save_pretrained(best_model_path)\n",
        "    print(f\"Best model saved for inference at {best_model_path}\")\n",
        "\n",
        "start_epoch = 0\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# If a checkpoint exists, load it; otherwise, initialize the model and tokenizer from scratch\n",
        "if os.path.exists(os.path.join(checkpoint_path, 'checkpoint.pth')):\n",
        "    print(\"Loading checkpoint...\")\n",
        "    model, optimizer, scheduler, start_epoch, best_val_loss = load_checkpoint(model, optimizer, scheduler, tokenizer, checkpoint_path, best_model_path)\n",
        "    model = model.to(DEVICE)\n",
        "    print(f\"Checkpoint loaded. Resuming training from epoch {start_epoch + 1}\")\n",
        "else:\n",
        "    print(\"No checkpoint found. Starting training from scratch.\")\n",
        "\n",
        "def train_and_save_best_model(model, tokenizer, train_dataloader, val_dataloader, optimizer, scheduler, epochs, device, start_epoch=0, best_val_loss=float('inf')):\n",
        "    training_stats = []\n",
        "\n",
        "    for epoch_i in range(start_epoch, epochs):\n",
        "        print(f'\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        progress_bar = tqdm(train_dataloader, desc=\"Training\", leave=False)\n",
        "\n",
        "        for step, batch in enumerate(progress_bar):\n",
        "            b_input_ids, b_attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            loss = model(b_input_ids, attention_mask=b_attention_mask, labels=b_input_ids).loss\n",
        "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "            total_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "            progress_bar.set_postfix({'Loss': f\"{loss.item():.4f}\"}, refresh=True)\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"\\nRunning Validation...\")\n",
        "        model.eval()\n",
        "        total_eval_loss = 0\n",
        "        progress_bar = tqdm(val_dataloader, desc=\"Validating\", leave=False)\n",
        "\n",
        "        for step, batch in enumerate(progress_bar):\n",
        "            b_input_ids, b_attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(b_input_ids, attention_mask=b_attention_mask, labels=b_input_ids)\n",
        "                loss = outputs.loss\n",
        "                total_eval_loss += loss.item()\n",
        "\n",
        "            progress_bar.set_postfix({'Loss': f\"{loss.item():.4f}\"}, refresh=True)\n",
        "\n",
        "        avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "        print(f\"\\n  Validation Loss: {avg_val_loss:.2f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            save_checkpoint(model, optimizer, scheduler, epoch_i, best_val_loss)\n",
        "            save_best_model_for_inference(model, tokenizer, best_model_path)  # Save best model for inference\n",
        "            print(\"New best model saved!\")\n",
        "\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'Epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Validation Loss': avg_val_loss,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(\"\\nTraining complete!\")\n",
        "\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "    df_stats = df_stats.set_index('Epoch')\n",
        "    print(df_stats)\n",
        "\n",
        "    sns.set(style='whitegrid', palette='deep', font_scale=1.1, rc={\"figure.figsize\": [8, 6]})\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label='Training')\n",
        "    plt.plot(df_stats['Validation Loss'], 'g-o', label='Validation')\n",
        "    plt.title('Training & Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.xticks(list(range(1, epochs+1)))\n",
        "    plt.show()\n",
        "\n",
        "train_and_save_best_model(model, tokenizer, train_dataloader, val_dataloader, optimizer, scheduler, EPOCHS, DEVICE, start_epoch, best_val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8JkE8H8D2Dnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bfa0d4-8853-438f-83f9-97be283c672f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oil, egg, onion1. heat oil in frying pan\n",
            "2. add egg and onion\n",
            "3. fry until golden brown\n",
            "4. drain on paper towels\n",
            "5. serve hot or cold\n",
            "6. makes 4 to 6 servings.1 1/2 cups flour, 1/4 teaspoon salt, 1 teaspoon baking powder, 2 teaspoons baking soda, 3/4 cup sugar, 1 1/\n"
          ]
        }
      ],
      "source": [
        "model_path = \"/content/drive/My Drive/ChefAI/best_model_for_inference\"\n",
        "\n",
        "# Load trained model and tokenizer from the saved model path\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "\n",
        "# Resize token embeddings\n",
        "#model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Set the device to GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def generate_recipe(ingredients, model, tokenizer, device, max_length=90, num_beams=5, no_repeat_ngram_size=3, num_return_sequences=1):\n",
        "    # Prepare the input text with special tokens\n",
        "    input_text = '<|startofrecipe|>''<|startofingre|>' + ingredients + '<|startofinstruc|>''<|endofrecipe|>'\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "    # Generate recipe using the model\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        num_beams=num_beams,\n",
        "        temperature=0.8,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Convert the generated tokens to text\n",
        "    generated_recipes = [tokenizer.decode(output[i], skip_special_tokens=True) for i in range(num_return_sequences)]\n",
        "\n",
        "    return generated_recipes\n",
        "\n",
        "# Test the function with an example\n",
        "ingredients = \"oil, egg, onion\"\n",
        "generated_recipes = generate_recipe(ingredients, model, tokenizer, device)\n",
        "print(generated_recipes[0])  # Print the first generated recipe"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f562ecbf0b53463d80045d3d43cf9223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab6e9d122e2c4216aeb0b0284eec95eb",
              "IPY_MODEL_cae8d6647ba74075ae9407cb21a0b720",
              "IPY_MODEL_552187e68fca4cecb4c42886b6faea8b"
            ],
            "layout": "IPY_MODEL_a107ae7eceeb4caf93b946a5e5b8cf14"
          }
        },
        "ab6e9d122e2c4216aeb0b0284eec95eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae67bbd91584471ab77db0a736aac4f0",
            "placeholder": "​",
            "style": "IPY_MODEL_2d36fedfd3bb49e8912038283aa7d9a9",
            "value": "Training:  54%"
          }
        },
        "cae8d6647ba74075ae9407cb21a0b720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566dd6b7d85e4ac8859311c1c00d1ad2",
            "max": 28125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_225f6e8bf876479aab8d042f6fa05d1f",
            "value": 15177
          }
        },
        "552187e68fca4cecb4c42886b6faea8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c59454cc7a54dbda8a4d419fc85b949",
            "placeholder": "​",
            "style": "IPY_MODEL_08f9c51057434a79bd815734fd89956d",
            "value": " 15177/28125 [1:38:24&lt;1:26:19,  2.50it/s, Loss=0.5949]"
          }
        },
        "a107ae7eceeb4caf93b946a5e5b8cf14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae67bbd91584471ab77db0a736aac4f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d36fedfd3bb49e8912038283aa7d9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "566dd6b7d85e4ac8859311c1c00d1ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225f6e8bf876479aab8d042f6fa05d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c59454cc7a54dbda8a4d419fc85b949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f9c51057434a79bd815734fd89956d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}